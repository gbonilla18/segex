SEPARATING MODEL AND VIEW - Model

Separation of concerns is achieved by minimizing the number of points of contact
between two functionally different parts of code (decoupling), which in turn is
achieved by minimization and formalization of points of communication. This may
seem obvious, but for some reason seems stressed more rarely than it should be
(i.e. perfect decoupling of code is almost always impossible, otherwise few
programmers would produce it in entangled form in the first place, so decoupling
typically comes down to refining points of communication).

The separation of model (data in SQL tables) and view (in-browser HTML) is
achieved via two intermediaries: Perl and JSON/Javascript. The data flow is as
follows:

    SQL -> Perl -> JSON -> HTML

We do this intentionally, to avoid the obvious shortcut:

    SQL -> Perl -> HTML

Skipping the JSON intermediary is not recommended because (1) it complicates
implementation of dynamic interfaces, and (2) when dynamic interfaces are
implemented, they have to deal with absence of clear separation between data and
presentation (i.e. between model and view). The second point becomes more clear
when we think in terms of the client page and what represents model, view and
controller there:

   --------   HTTP   -------                        ------
  | SERVER | =====> | JSON  | ===================> | HTML |
  |        |        | HEAD  |                      | BODY |
  |        |        | model | =>  ------------  => | view |
  |        |         -------  <- | Javascript | <-  ------
  |        | ==================> | .js files  |      |
   --------  <------------------ | controller |      |
                      AJAX        ------------       |
             <---------------------------------------
                      HTTP GET/POST to CGI controller

                   |________________ VIEW ________________|

The above is a "zoomed-in" view focusing on the client. There is a whole new
separate MVC subsystem on the client, with its own model, view, and controller
-- and this subsystem is embedded within the "view" part of the overall MVC
superstructure.

If we were to directly write data model to HTML (for example, by filling in a
select box with dynamic data), dynamic interactions on the user's side would
require either constant HTTP requests or looking up data from the DOM tree. We
want to avoid this because such lookups are (1) inefficient, (2) can easily lead
to corruption of view because they introduce circular dependencies where HTML is
updated with data collected from previous HTML state and so on. Writing model as
JSON introduces directionality and avoids such "incestuous" dependencies of
content on itself.  Doing so also lends itself to easy introduction of AJAX
where need for it exists.

All dynamic data (i.e. contents of tables, dropdown lists, etc.) should be
written as JSON to page header (never inside <BODY> tag!). The JSON data should
be formed first as native Perl data structures and converted to JSON with the
use of JSON::XS module. For example, we do not want this:

    my $out = 'var contents = ';
    for (@result_array) {
        my $col1 = $_->[3];
        my $col2 = $_->[1];
        # backslash double quotes
        $col1 =~ s/"/\\"/g;
        $col2 =~ s/"/\\"/g;
        $out .= '{"probe":"' . $col1 . '","gene":"' . $col2 . '"}' . ',';
    }
    $out =~ s/,\s*$//;
    return "$out;\n";

Such code increases coupling between Perl and Javascript, which is bad, because,
when writing it, we have to worry about the different syntaxes of these two
languages at once, which makes our code more error prone and our coding slower.
Instead, we write:

    use JSON::XS;

    my @tmp;
    for (@result_array) {
        push @tmp, { probe => $_->[3], gene => $_->[1] };
    }
    return sprintf(
        "var contents = %s;\n",
        encode_json(\@tmp)
    );

Or using functional style,

    use JSON::XS;

    return sprintf(
        "var contents = %s;\n",
        encode_json([ 
            map { { probe => $_->[3], gene => $_->[1] } } 
            @result_array
        ])
    );

Because we first form a Perl data structure in the second example, if we make a
typo, for example, Perl will let us know about it right away. Similarly,
JSON::XS ensures that the Perl data structure is encoded as valid Javascript
without needing to backslash double quotes manually.

CONTROLLER

CONTROLLER - General

Considering the use of CGI::Application to handle dispatching of requests. If
initial trial/validation succeeds, this will be the recommended framework.

There should be a "tree" of user actions. Index.cgi should only take care of
dispatching top-level actions in the tree. The modules (ManageProjects,
ManageStudies, ManageExperiments, etc.) should dispatch actions at the remaining
level(s). Top-level actions are called with "a=" parameter, second-level actions
are called with "b=" parameter and so on. Since the parameter is one-letter
only, action names should be descriptive by themselves. Object constructors are
passed a reference to an array of Javascript includes, since only modules will
know which Javascript files they need.  Constructors must not print anything to
screen.  Constructors will almost always be passed the database handle and may
also be passed session object handle. The array of Javascript includes simply
contains relative paths of Javascript files to load; after top-level dispatch is
complete, it is transformed to convert relative paths to absolute and is sent to
CGI.pm.

CONTROLLER - SGX::Manager abstract class

Define an abstract class supporting typical manage operations (update one field,
delete record) as AJAX requests and some less frequent manage operations (enter
new record / update a number of fields simultaneously) as typical CGI requests.
Currently, the module expressing similar functionality most closely is
SGX::ManageExperiments. It should be renamed to SGX::ExperimentManager. The
following inheritance hierarchy will be implemented

                      SGX::Manager
                  /   |             \               \
                /     |              |                \
SGX::UserManager SGX::ProjectManager SGX::StudyManager SGX::ExperimentManager


When passing arguments to module constructors, prefer named arguments. For
example: my $findProbes = SGX::FindProbes->new(dbh => $dbh, cgi => $q, session
=> $s).


VIEW - The "right" way

The "right" way to deal with View, according to some CGI::Application
documentation, is to use HTML::Template. Right now I am leaning strongly against
using any kind of HTML templates. The reasoning is that the HTML we use is very
basic and unlikely to change, while all the "meat" of the view is handled by the
YUI Javascript framework and by Javascript files in the js/ folder. The
CGI::Application documentation was written in an era before AJAX and does not
consider the modern way of building web apps. So all the "view" complexity is
already removed from HTML and delegated to Javascript, for which we do have
template-like individual files (albeit in .js format) in the js/ folder.

Another argument against HTML::Template is that the whole idea of an HTML
template is to reduce coupling between Perl and HTML. However, if we confine
ourselves to pure CGI.pm, we do not have any coupling -- all HTML is represented
as Perl objects in a one-to-one correspondence before being generated by CGI.
From this point of view, we do not reduce coupling by using an HTML template --
we increase it instead. It seems to me that templates were designed in a world
where programmers and designers had difficulties conceptualizing that HTML could
be represented as a tree-like Perl object; probably because templates were
originally meant for non-interpreted languages that did not allow such tree-like
structures. This would explain why Common Lisp and Clojure people use a
CGI.pm-like approach by representing HTML first in Lisp.

The third and final argument against HTML::Template is that it is inflexible --
for example, if we wanted to change from XHTML 1.1 to HTML 4.0, we would need to
rewrite a bunch of template files, while with CGI.pm the changeover involves
setting a small switch at the construction/initialization of the CGI object.

To conclude, it appears that we will be using CGI::Application with CGI.pm and
custom classes for model.


REST ARCHITECTURE

Except for special cases (for example when file upload control is present), all
forms should be sent as GET requests instead of POST. Whenever a form uses GET
method, its enctype property must be set to "application/x-www-form-urlencoded"
("multipart/form-data" creates a binary stream which doubles the traffic).  The
URLs should be short enough and human readable enough that they could be
modified by the user. Care should be taken that, in case a link is shared via
email, the resulting page looks the same regardless of who the user is or what
computer he or she uses. To achieve this goal, all state information should be
expressly specified in the form of URL parameters in the GET request.

HTML

Generated HTML should be valid. Since most pages being worked on are private, it
is cumbersome to validate their source using the W3C service. This can be worked
around by using Total Validator Firefox plugin and the accompanying Mac or
Windows application.

PERL

Perl::Critic and Perl::Tidy are recommended. Vim plugin "perl-support" (see Vim
site for download) lets one run Perl::Critic and Perl::Tidy on current source
with onlyn a few keystrokes (\rc and \ry respectively). Additional nicety of
perl-support is that it lets one quickly generate "framed" comments (\cfr),
module method headers (\cm), function headers (\cfu) and so on. Equivalent
plugin is available for C (called "c-support"), with most key mappings being the
same.

JAVASCRIPT

Avoid using onclick and onchange properties of DOM elements. Instead, use the
addListener function from the YUI library and place corresponding code in the
<HEAD> element.

SQL

SQL - General

In Find Probe, we attempt to retrieve all probes related to each other through
gene symbols or accession numbers. The probe table joined with the annotation
table forms an *adjacency list* of probe ids, so the problem we are looking at
is recursively extracting all probes related to queried ones based on that
adjacency list. The current implementation only goes one level deep in the list.
Illustration:

   Probes          Accnum
      x --------> 12321  # x links to 12321
               /
      y ------           # y links to both 12321 and 3423
               \
      z --------> 3423   # z links to 3423

When searching for probe "x", Find Probes will also return probe "y" because it
links to the same accession number as "y". It will not, however, return probe
"z", even though "z", since it shares an accession number with "y", could be
strongly associated with both x and y. Returning all three probes (and any
others linked in this way) would require a recursive traversal of the bipartite
graph formed by the sets of probes, accession numbers, and their relations.
MySQL does not support recursive queries; however PostgreSQL has a "WITH
RECURSIVE q AS () SELECT FROM q" statement where, inside the parentheses, we
select the zeroth level with WHERE clause from a table (call it Table A) and
then combine it using UNION statement with a JOIN of Table A and q.

http://explainextended.com/2009/09/24/adjacency-list-vs-nested-sets-postgresql/

SQL - Performance

With Perl code, performance should not be the main consideration, but it is the
main consideration with SQL, trumping readability (and nearly everything else).
Strategies for best database performance: (1) joins are the most expensive
operations; try to reduce the number of joins if possible; (2) LEFT and RIGHT
joins are usually more expensive than INNER joins (3) try to minimize the number
of rows searched early on, using subqueries or INNER joins, (4) benchmark all
queries, (5) try to rewrite a slow query in several alternative ways (for
example, using RIGHT joins instead of LEFT etc.) and then benchmark all of them,
(6) ensure that all commonly performed JOINS operate on indexed columns or
combinations of columns; create necessary indexes otherwise, (7) use query
optimizer (EXPLAIN statement) to decide which columns should be indexed and to
track the progress of the query and the number of rows it operates on. (8) avoid
using NATURAL joins (this is more of a maintainability issue but may affect
performance because it obscures what really happens in the query), (9) avoid
using DISTINCT modifier (prefer GROUP BY clause instead, since it allows you to
enter specific column names on which to perform grouping; preference should go
to those columns that are indexed keys). (10) use DBI::Profile to monitor
performance, (11) use DBI placeholders (more of a security issue but may affect
performance when the same query is executed repeatedly with different input
parameters). (12) consider using prepare_cached() DBI function instead of
prepare(). (13) indexes on columns that may contain long text are suboptimal.

VISUALIZATION

Consider using g.Raphael Javascript framework for drawing graphs inside the
client browser window from JSON data obtained from the server (as opposed to
generating SVG files on the server as it is set up currently).
https://github.com/mobz/g.raphael
https://github.com/alexyoung/ico

THEORY

THEORY - Compare Experiments

Compare Experiments produces a list of significant probes in the selected
experiments. A probe is called significant if it satisfies P<0.05 and
|foldchange|>x in at least one of the selected experiments.

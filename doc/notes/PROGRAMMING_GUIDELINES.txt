1. Model-View-Controller Pattern

1.1 SEPARATING MODEL AND VIEW - Model

Separation of concerns is achieved by minimizing the number of points of contact
between two functionally different parts of code (decoupling), which in turn is
achieved by minimization and formalization of points of communication. This may
seem obvious, but for some reason seems stressed more rarely than it should be
(i.e. perfect decoupling of code is almost always impossible, otherwise few
programmers would produce it in entangled form in the first place, so decoupling
typically comes down to refining points of communication).

The separation of model (data in SQL tables) and view (in-browser HTML) is
achieved via two intermediaries: Perl and JSON/Javascript. The data flow is as
follows:

    SQL -> Perl -> JSON -> HTML

We do this intentionally, to avoid the obvious shortcut:

    SQL -> Perl -> HTML

Skipping the JSON intermediary is not recommended because (1) it complicates
implementation of dynamic interfaces, and (2) when dynamic interfaces are
implemented, they have to deal with absence of clear separation between data and
presentation (i.e. between model and view). The second point becomes more clear
when we think in terms of the client page and what represents model, view and
controller there:

   --------   HTTP   -------                        ------
  | SERVER | =====> | JSON  | ===================> | HTML |
  |        |        | HEAD  |                      | BODY |
  |        |        | model | =>  ------------  => | view |
  |        |         -------  <- | Javascript | <-  ------
  |        | ==================> | .js files  |      |
   --------  <------------------ | controller |      |
                      AJAX        ------------       |
             <---------------------------------------
                      HTTP GET/POST to CGI controller

                   |________________ VIEW ________________|

The above is a "zoomed-in" view focusing on the client. There is a whole new
separate MVC subsystem on the client, with its own model, view, and controller
-- and this subsystem is embedded within the "view" part of the overall MVC
superstructure.

If we were to directly write data model to HTML (for example, by filling in a
select box with dynamic data), dynamic interactions on the user's side would
require either constant HTTP requests or looking up data from the DOM tree. We
want to avoid this because such lookups are (1) inefficient, (2) can easily lead
to corruption of view because they introduce circular dependencies where HTML is
updated with data collected from previous HTML state and so on. Writing model as
JSON introduces directionality and avoids such "incestuous" dependencies of
content on itself.  Doing so also lends itself to easy introduction of AJAX
where need for it exists.

All dynamic data (i.e. contents of tables, dropdown lists, etc.) should be
written as JSON to page header (never inside <BODY> tag!). The JSON data should
be formed first as native Perl data structures and converted to JSON with the
use of JSON::XS module. For example, we do not want this:

    my $out = 'var contents = ';
    for (@result_array) {
        my $col1 = $_->[3];
        my $col2 = $_->[1];
        # backslash double quotes
        $col1 =~ s/"/\\"/g;
        $col2 =~ s/"/\\"/g;
        $out .= '{"probe":"' . $col1 . '","gene":"' . $col2 . '"}' . ',';
    }
    $out =~ s/,\s*$//;
    return "$out;\n";

Such code increases coupling between Perl and Javascript, which is bad, because,
when writing it, we have to worry about the different syntaxes of these two
languages at once, which makes our code more error prone and our coding slower.
Instead, we write:

    use JSON::XS;

    my @tmp;
    for (@result_array) {
        push @tmp, { probe => $_->[3], gene => $_->[1] };
    }
    return sprintf(
        "var contents = %s;\n",
        encode_json(\@tmp)
    );

Or using functional style,

    use JSON::XS;

    return sprintf(
        "var contents = %s;\n",
        encode_json([ 
            map { { probe => $_->[3], gene => $_->[1] } } 
            @result_array
        ])
    );

Because we first form a Perl data structure in the second example, if we make a
typo, for example, Perl will let us know about it right away. Similarly,
JSON::XS ensures that the Perl data structure is encoded as valid Javascript
without needing to backslash double quotes manually.

Note 1: The pattern discussed above is basically the Two-Step View pattern from
Martin Fowler's book:
http://martinfowler.com/eaaCatalog/twoStepView.html

Note 2: Another commonly-used pattern in web applications is Template View. Our
current architecture actually discourages the use of Template View, and for a
good reason: forming AJAX data on the server and then filling them into view
using Javascript and element IDs actually gives us better guarantees about view
correctness than filling in placeholders into an HTML template on the server and
then sending it to the client. This is so for two reasons: (1) we use CGI.pm to
first form an abstract representation of the HTML view using native Perl data
structures which ensures that different types of HTML (HTML, XHTML, etc) can be
formed correctly, (2) Filling in values using Javascript and element IDs
requires correct DOM tree to begin with and is therefore more robust than
filling in placeholders in a text-blob template.




1.2 CONTROLLER

1.2.1 CONTROLLER - General

Considering the use of CGI::Application to handle dispatching of requests. If
initial trial/validation succeeds, this will be the recommended framework.

There should be a "tree" of user actions. Index.cgi should only take care of
dispatching top-level actions in the tree. The modules (ManageProjects,
ManageStudies, ManageExperiments, etc.) should dispatch actions at the remaining
level(s). Top-level actions are called with "a=" parameter, second-level actions
are called with "b=" parameter and so on. Since the parameter is one-letter
only, action names should be descriptive by themselves. Object constructors are
passed a reference to an array of Javascript includes, since only modules will
know which Javascript files they need.  Constructors must not print anything to
screen.  Constructors will almost always be passed the database handle and may
also be passed session object handle. The array of Javascript includes simply
contains relative paths of Javascript files to load; after top-level dispatch is
complete, it is transformed to convert relative paths to absolute and is sent to
CGI.pm.

1.2.2 CONTROLLER - SGX::CRUD abstract class

Define an abstract class supporting typical CRUD operations (create, read,
update, delete) as AJAX or regular requests.  Currently, the module expressing
similar functionality most closely is SGX::ManageExperiments. It should be
renamed to SGX::CRUD::Experiment. The following inheritance hierarchy will be
implemented

                      SGX::CRUD
                  /   |             \               \
                /     |              |                \
SGX::CRUD:User SGX::CRUD::Project SGX::CRUD::Study SGX::CRUD::Experiment

When passing arguments to module constructors, prefer named arguments. For
example: my $findProbes = SGX::FindProbes->new(dbh => $dbh, cgi => $q, session
=> $s). (Note: this was replaced with %controller_context hash).

The SGX::CRUD abstract class will be a composite class, containing controller,
model, and basic view methods (though those methods could be abstracted away
into their own MVC classes).

See CatalystX::CRUD perldoc for an example of how we want this to be:
http://search.cpan.org/search?query=crud+catalystx



1.3 VIEW

1.3.1 VIEW - The "right" way

The "right" way to deal with View, according to some CGI::Application
documentation, is to use HTML::Template. Right now I am leaning strongly against
using any kind of HTML templates. The reasoning is that the HTML we use is very
basic and unlikely to change, while all the "meat" of the view is handled by the
YUI Javascript framework and by Javascript files in the js/ folder. The
CGI::Application documentation was written in an era before AJAX and does not
consider the modern way of building web apps. So all the "view" complexity is
already removed from HTML and delegated to Javascript, for which we do have
template-like individual files (albeit in .js format) in the js/ folder.

Another argument against HTML::Template is that the whole idea of an HTML
template is to reduce coupling between Perl and HTML. However, if we confine
ourselves to pure CGI.pm, we do not have any coupling -- all HTML is represented
as Perl objects in a one-to-one correspondence before being generated by CGI.
From this point of view, we do not reduce coupling by using an HTML template --
we increase it instead. It seems to me that templates were designed in a world
where programmers and designers had difficulties conceptualizing that HTML could
be represented as a tree-like Perl object; probably because templates were
originally meant for non-interpreted languages that did not allow such tree-like
structures. This would explain why Common Lisp and Clojure people use a
CGI.pm-like approach by representing HTML first in Lisp.

The third and final argument against HTML::Template is that it is inflexible --
for example, if we wanted to change from XHTML 1.1 to HTML 4.0, we would need to
rewrite a bunch of template files, while with CGI.pm the changeover involves
setting a small switch at the construction/initialization of the CGI object.

To conclude, it appears that we will be using CGI::Application with CGI.pm and
custom classes for model.

1.3.2. HTML

Generated HTML should be valid. Since most pages being worked on are private, it
is cumbersome to validate their source using the W3C service. This can be worked
around by using Total Validator Firefox plugin and the accompanying Mac or
Windows application.


1.3.3 Dynamic elements

Avoid using 'onclick' and 'onchange' attributes of DOM elements. Instead, use
the addListener function from the YUI library and place corresponding code in
the <HEAD> element.

1.3.4 Data visualization

Consider using g.Raphael Javascript framework for drawing graphs inside the
client browser window from JSON data obtained from the server (as opposed to
generating SVG files on the server as it is set up currently).
https://github.com/mobz/g.raphael
https://github.com/alexyoung/ico





2. REST ARCHITECTURE

2.1 REST: GET vs POST

Except for special cases (for example when file upload control is present), all
forms should be sent as GET requests instead of POST. Whenever a form uses GET
method, its 'enctype' attribute must be set to
"application/x-www-form-urlencoded" ("multipart/form-data" which is default in
CGI.pm creates a binary stream which doubles the traffic). Because URL
parameters in the 'action' attribute of a form element may interfere with form
input fields, instead of doing action="?x=blah" we should instead create a
hidden field in the form that stores the desired value of "x". The above applies
for GET forms only -- for POST forms, it is okay to specify URL parameters in
the 'action' attribute directly as long as they are read with url_param on
processing. 

The above entails that top-level and second-level "resources" should be read
using CGI::url_param() while all other non-RESTful state information should be
read using CGI::param(). Correct use of url_param and param would reflect the
conceptual separation between "resource" and "state".

Alternative approach is possible: use 'action' attribute for URL parameters that
identify unique and relatively permanent resources that are accessed more or
less often. Such resources are, for example, first-level branches ('a='
parameter) and ids of items in a collection.

Plain URLs *must not* be used to affect resource states.  The following is a
very short reason why: any plain link should be crawlable, regardless of whether
it is behind password protection (one day, for specific reources, or even by
accident, password protection may be removed, and we *really, really* do not
want a web crawler to delete every resource on the site that has a delete link.

Instead of creating "Delete" and "Remove" links, we should be
create forms with textual submit buttons. Alternatively, we could submit an AJAX
POST request to delete these resources from the table. This would be in
agreement with the "RESTful Web Services Cookbook" (pp. 13-15): "Use GET for
safe and idempotent information retrieval. ... Use POST ... To create a new
resource ... To modify one or more resources via a controller resource ... To
run queries with large inputs ... To perform any unsafe or nonidempotent
operation when no other HTTP method seems appropriate".

The URLs should be short enough and human readable enough
that they could be modified by the user. Care should be taken that, in case a
link is shared via email, the resulting page looks the same regardless of who
the user is or what computer he or she uses. To achieve this goal, all state
information should be expressly specified in the form of hidden fields in the
form performing the GET request.

"The REST cookbook –- a fantastic write-up which I do strongly recommend –-
suggests to identify commonly used search criteria and expose those queries as
separate resources."
http://nicksda.apotomo.de/2011/06/rails-misapprehensions-query-parameters-are-restful/

"[Speaking of POST...] The param() method will always return the contents of the
POSTed fill-out form, ignoring the URL's query string. To retrieve URL
parameters, call the url_param() method. ... The main difference is that
url_param() allows you to read the parameters, but not set them. ... If you try
to mix a URL query string with a form submitted with the GET method, the results
will not be what you expect."
http://perldoc.perl.org/CGI.html#MIXING-POST-AND-URL-PARAMETERS

Perl documentation suggests that for GET forms, URL query string in the 'action'
attribute should not contain URL parameters because they may interfere with
input field names present in the form. For POST names, those parameters are
guaranteed not to interfere with field names because of the url_param/param
separation.

"If the form was submitted with GET, both param() and url_param() return the
parameters from the URL. If the form was submitted with POST but also had URL
parameters thrown in too, then param() returns only the POSTed parameters and
url_param() returns only the URL ones."
http://www.garayed.com/perl/75096-cgi-pm-distinguish-between-post-get-3.html#post335175

2.2 REST - Error Codes

For reference on HTTP error codes, see REST cookbook, pp. 71-72.






4. Perl

4.1 Perl - General

Perl::Critic and Perl::Tidy are recommended. Vim plugin "perl-support" (see Vim
site for download) lets one run Perl::Critic and Perl::Tidy on current source
with only a few keystrokes (\rc and \ry respectively). Additional nicety of
perl-support is that it lets one quickly generate "framed" comments (\cfr),
module method headers (\cm), function headers (\cfu) and so on. Equivalent
plugin is available for C (called "c-support"), with most key mappings being the
same.

4.2 Object-Oriented Programming

Perl doesn't have attribute inheritance, and even if it did (via some CPAN
package), it would "introduce a tremendous amount of coupling between an
inherited class and a derived class" (Advanced Perl Programming, O'Reilly,
section 8.3.1).

Therefore, if we want to use inheritance, we should avoid introducing
specialization into attributes. For example, when we have two classes that
interact with two similar database tables and one of them (the class that
interacts with the larger of the two tables) inherits from another, we do not
want to store SQL queries as attributes because that way they cannot be
overridden during inheritance. On the other hand, Perl allows for method
inheritance, so all SQL queries should be declared and used directly inside
methods (if there is a need to separate the declaration/preparation from
execution, then create two different methods).


4.3. Exceptions

Use SGX::Exceptions. 

User exceptions (SGX::Exception::User) are messages to user; internal exceptions
(SGX::Exception::Internal) are messages for internal development purposes.
Showing internal exceptions to user may pose a security risk.

Because we use Class::Exception::DBI module, DBI exceptions have the same
interface. When you need to communicate a DBI error (e.g. duplicate record) to
user, do not show DBI exception to user directly -- instead re-throw it as User
exception with a custom message.

4.4 I/O

CSV format should be supported in addition to tab-delimited. The idea is that
the same formats that are supported for output should also be supported for
input.

4.5 DEFAULT ARGUMENTS TO PERL SUBROUTINES

The following snippet is from the constructor to File::Temp in default Perl
installation. It shows an example of how default arguments could be used by a
subroutine. We should not be converting to uppercase unless special behavior is
desired, but the example below shows how it could be done when needed. Note that
exists() is used instead of defined() to set defaults. This allows the user to
use the following: my $tmp = File::Temp->new(UNLINK => undef); to set UNLINK to
false.  Since undefined value evaluates to false, we should allow for the use of
undef in such situations. We may not want to delete argument from argument
lists, however, since it may result in ambiguity. For example, $args{UNLINK}
evaluates to false after UNLINK has been deleted from the argument list.

  # read arguments and convert keys to upper case
  my %args = @_;
  #%args = map { uc($_), $args{$_} } keys %args;

  # see if they are unlinking (defaulting to "yes")
  my $unlink = (exists $args{UNLINK} ? $args{UNLINK} : 1 );
  #delete $args{UNLINK};

If the named argument defaulted to "no", we could simply assign it:

  my $unlink = $args{UNLINK};



6. SQL

6.1. SQL - Design issues - Views

Avoid repeating data. For example, if columns A and B are combined to produce
some value over large number of rows, do not cache the result in column C -- use
SQL views instead. A specific example where SQL views are needed is the
corrected P-value column in the main data/response table.


6.2 SQL - Graph traversal

In Find Probe, we attempt to retrieve all probes related to each other through
gene symbols or accession numbers. The probe table joined with the annotation
table forms an *adjacency list* of probe ids, so the problem we are looking at
is recursively extracting all probes related to queried ones based on that
adjacency list. The current implementation only goes one level deep in the list.
Illustration:

   Probes          Accnum
      x --------> 12321  # x links to 12321
               /
      y ------           # y links to both 12321 and 3423
               \
      z --------> 3423   # z links to 3423

When searching for probe "x", Find Probes will also return probe "y" because it
links to the same accession number as "y". It will not, however, return probe
"z", even though "z", since it shares an accession number with "y", could be
strongly associated with both x and y. Returning all three probes (and any
others linked in this way) would require a recursive traversal of the bipartite
graph formed by the sets of probes, accession numbers, and their relations.
MySQL does not support recursive queries; however PostgreSQL has a "WITH
RECURSIVE q AS () SELECT FROM q" statement where, inside the parentheses, we
select the zeroth level with WHERE clause from a table (call it Table A) and
then combine it using UNION statement with a JOIN of Table A and q.

http://explainextended.com/2009/09/24/adjacency-list-vs-nested-sets-postgresql/

6.3 SQL - Performance

While with Perl code, performance should not be the main consideration, but it
is the main consideration with SQL, trumping readability (and nearly everything
else).  Strategies for best database performance: (1) joins are the most
expensive operations; try to reduce the number of joins if possible; (2) LEFT
and RIGHT joins are usually more expensive than INNER joins (3) try to minimize
the number of rows searched early on, using subqueries or INNER joins, (4)
benchmark all queries, (5) try to rewrite a slow query in several alternative
ways (for example, using RIGHT joins instead of LEFT etc.) and then benchmark
all of them, (6) ensure that all commonly performed JOINS operate on indexed
columns or combinations of columns; create necessary indexes otherwise, (7) use
query optimizer (EXPLAIN statement) to decide which columns should be indexed
and to track the progress of the query and the number of rows it operates on.
(8) avoid using NATURAL joins (this is more of a maintainability issue but may
affect performance because it obscures what really happens in the query), (9)
avoid using DISTINCT modifier (prefer GROUP BY clause instead, since it allows
you to enter specific column names on which to perform grouping; preference
should go to those columns that are indexed keys). (10) use DBI::Profile to
monitor performance, (11) use DBI placeholders (more of a security issue but may
affect performance when the same query is executed repeatedly with different
input parameters). (12) consider using prepare_cached() DBI function instead of
prepare(). (13) indexes on columns that may contain long text are suboptimal.

Partial word matches in databases do not use indexes, so do not use REGEXP
'^(word1|word2)$' for matching "word1" and "word2", and instead either use WHERE
IN predicate or JOIN with a TEMPORARY table.

6 THEORY

6.1 THEORY - Compare Experiments

Compare Experiments produces a list of significant probes in the selected
experiments. A probe is called significant if it satisfies P<0.05 and
|foldchange|>x in at least one of the selected experiments.



